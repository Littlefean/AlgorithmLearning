视频做不动了，还是先写出一个文案出来吧。

## 蒙特卡洛1.0

假如你要下井字棋，现在棋盘上有九个点可以落子，那么你可以用随机模拟的方式对这九个点进行模拟很多次，最后看看哪个点胜率最高，就下哪个点就可以了。

这种方法非常简单，叫平坦蒙特卡洛搜索。不建立树结构，可以用于非常简单、或者资源受限制的情况。

但缺点也很明显，下一步棋之后展开的可能性太多了，要建立树结构

## 蒙特卡洛2.0

在上面随机下棋的基础上建立树结构，每下一步都添加到树的节点。

可以想想本来全部棋局可能性是一个非常庞大的树，并把这个树设置为半透明，不停的在这个树上模拟的过程就相当于把里面的一些部分设置为完全不透明。我们不需要像minimax或者alphabeta那样，完整的遍历这个树。

虽然alpha-beta不是完整的遍历了树，他是通过剪枝的方法没有遍历很多地方。但实际上在逻辑上相当于没有疏漏。该看过的地方都看过了。

还需要提的是，我在比特山上运行的井字棋的alpha-beta是搜索了全部，运行时间很长，但由于井字棋规模小，和别人对打不会超时，但是用这个算法和别人打五子棋就绝对超时了，必须限制树的**高度**。我记得限制了两步，树的整体高度是3。同时**宽度**我也进行了限制，我只拿取棋子周边边缘的空地作为下一步的可下位置。

蒙特卡洛不一样，它生成树的过程是随机的，因此在逻辑上有疏漏。

为什么要建立树结构？如果只是建立树结构，但本质每次模拟的时候都是随机的，那么和1.0没有什么区别，甚至还占用内存空间了。

建立树的节点的目的，就是为了**“记忆”**，上次下过这个地方，这次模拟到的时候，就发现上次已经下到过这个局面了。

因此，每个节点上还要绑定一些额外的属性：**“胜率”**来作为记录信息。表示当前局面，你的胜率是多少。

> 欸，那么这个时候又有人想问了，上次在讲minimax和alpha-beta的时候，也是画了一个挺大的树结构，为什么在那个代码里不用写出树的数据结构，而是用递归来写的。用递归其实是按照一定的顺序遍历了这个逻辑上抽象意义的树。
>
> 所以在递归函数压栈弹栈的时候就已经实现了树的一条从根节点到叶子节点的纵向结构建立。
>
> 但是蒙特卡洛随机模拟的过程是毫无顺序的，所以需要额外的空间来建立树结构来做保存。

如果你是非常熟悉数据结构与算法了，你会觉得上面的是废话

为了给每一个局面节点绑定额外的**胜率属性**，需要在一次模拟到树的叶子或者分出胜负、或者可以分出胜负时候，就开始反向传播，这个反向传播可以通过递归的结束位置实现。

属性可以这样：

```js
{
	cout: 1,
    win: 1,
}
```

每次经过这个节点的时候就动态的计算一下，win / count 。

赢了就反向传播，让途径的每一个节点的count++，win++。如果是输了就 只 count++。

这样你第二次来到有记录的节点的时候，就可以看看这个有记录的节点的所有子节点，选择胜率最高的那个子节点走下去。

这个时候要注意，如果当前局面时对手要下了，就选择胜率最低的那个子节点走下去，这个思想和前面两期视频类似。

因为对手会想办法阻止我们胜。

这个时候又有一个大问题，还没有访问过的节点怎么计算胜率？

就从数学意义上认为他们相除之后是无穷大，所以我们认为应该优先探索没有下过的局面。如果存在多个无穷大，就随便挑一个无穷大局面或者按着一个默认的顺序就可以。

你也可以认为是无穷小，这样你就能充分的利用自己曾经走过的分支。

那么你到底是要充分的探索还是充分的利用？这个你都可以试试，不同的棋类游戏可能有不同的设置。

但这个2.0是我自己为了帮助理解，提前编出来的，其实是3.0的简化。**接下来的3.0就是为了优化你是应该充分探索还是充分利用的问题。**

为了限制树的**高度**：你可以写一个判断局面是否已经结束了的或者马上就要结束的函数。

为了限制树的**宽度**：你就需要一个**“局面评估函数”**，输入一个局面，返回这个局面上一部分可以下的可下点的坐标，或者按照价值程度来划分一下。

## 蒙特卡洛3.0

对于围棋来说，一开始胜率低的下法在后期会变成极大的优势。

现在每个局面节点上记录的属性不再是“胜率”值了，而是，**搜索价值**。

搜索价值我们用UCB（Upper Confidence Bound）表示，UCB值越大，表示越应该选择这个节点。

实际上在其他地方还能看到 UCT（Upper Confidence Bound applied to Trees），实际上本质是一样的，只不过是把这个公式应用到树上了。

这个值怎么计算？UCB = 胜率 + 遗憾值

遗憾值 = 父节点访问次数 / 子节点访问次数

但实际上真正的遗憾值是：父节点访问次数要套一层log，然后整个遗憾值还要开个根号缓和一下。

之所以这样做可能是为了让整个值的变化更加稳定一些。

然后再加个参数c，UCB = 胜率 + c · 遗憾值。

这样可以通过调整参数c，来制定你是更偏向利用还是更偏向探索的策略。

向下走的时候选择策略：

```
当前是叶（或者已经到了高度截断点）：
	没访问过：
		模拟
	访问过：
		展开生成新节点并选第一个子节点继续
当前非叶：
	直接选UCB值最大的子节点，继续上述操作。
```

上面的展开就是生成新节点。

总体来说就是四步：选择、扩展、模拟、反向传播。

实际上这里有点乱了，可以采取不用展开的方法，没生成的节点就按没访问过算，UCB值就是无穷大。

然后rollout模拟的时候也生成节点，这样树生长出来的节点就是一缕一缕纵向的。

最终统计，找到胜率最高的那个根节点的子节点，就OK了。



参考资料：

[Sci-Hub | A Survey of Monte Carlo Tree Search Methods | 10.1109/tciaig.2012.2186810](https://sci-hub.yt/10.1109/tciaig.2012.2186810)

